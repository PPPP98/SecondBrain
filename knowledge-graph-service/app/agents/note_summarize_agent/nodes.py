import asyncio
import trafilatura
import json
import logging
from typing import Any
from .state import State
from .models import Models
from .prompts import Prompts

logger = logging.getLogger(__name__)


class Nodes:
    """
    ## ë…¸íŠ¸ ìš”ì•½ Agent ë…¸ë“œ
    - data ì¶”ì¶œ
    - ì¶”ì¶œ ë°ì´í„° ìš”ì•½

    """

    @staticmethod
    async def _extract_content(url: str) -> str:
        """
        ## urlì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜
        : trafilatura ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
        ### Returns:
            str: ì¶”ì¶œ ë‚´ìš©
        """
        try:
            logger.debug(f"ğŸŒ Fetching URL: {url}")
            downloaded = await asyncio.to_thread(
                trafilatura.fetch_url,
                url,
            )
            if not downloaded:
                logger.warning(f"trafilatura No response")
                return ""

            result = await asyncio.to_thread(
                trafilatura.extract,
                downloaded,
                output_format="json",
                include_comments=False,
                include_links=False,
                with_metadata=True,
            )
            if not result:
                logger.warning("trafilatura No content")
                return ""

            parsed = json.loads(result)
            title = parsed.get("title", "Untitled")
            text = parsed.get("text", "")

            if not text:
                logger.warning("trafilatura Empty text")
                return ""

            content = f"## {title}\n\n{text}"
            logger.debug(f"âœ… ({len(text)} chars)")

            return content

        except Exception as e:
            logger.error(f"error: {e}")
            pass

    @staticmethod
    def _is_url(text: str) -> bool:
        """URL ì—¬ë¶€ íŒë‹¨"""
        return text.startswith("http://") or text.startswith("https://")

    @staticmethod
    async def extract_node(state: State) -> dict[str, Any]:
        """
        Node 1: data â†’ content ë³€í™˜

        - URL (http/https): Trafilaturaë¡œ ë³¸ë¬¸ ì¶”ì¶œ
        - í…ìŠ¤íŠ¸: ê·¸ëŒ€ë¡œ ì‚¬ìš©
        """
        logger.debug(f"\nğŸ”„ [EXTRACT] Processing {len(state['data'])} items")

        contents = []

        for idx, item in enumerate(state["data"], 1):
            logger.debug(f"   [{idx}/{len(state['data'])}]")

            if Nodes._is_url(item):
                # URL ì²˜ë¦¬
                logger.debug(f"      URL: {item[:60]}...")
                content = await Nodes._extract_content(item)

                if content:
                    contents.append(item + content)
                    logger.debug(f"      âœ… Extracted")
                else:
                    logger.warning(f"      âš ï¸ Failed")
            else:
                # í…ìŠ¤íŠ¸ ì²˜ë¦¬
                logger.debug(f"      TEXT: {item[:60]}...")
                contents.append(item)
                logger.debug(f"      âœ… Added ({len(item)} chars)")

        logger.debug(f"\nğŸ“Š Result: {len(contents)}/{len(state['data'])} items")

        return {"content": contents}

    @staticmethod
    async def summarize_node(state: State) -> dict[str, Any]:
        """
        Node 2: content â†’ result ë³€í™˜ (LLM ìš”ì•½)
        """
        logger.debug(f"\nğŸ“ [SUMMARIZE]")

        if not state["content"]:
            logger.warning("   âš ï¸ No content to summarize")
            return {"result": ""}

        # ëª¨ë“  content ê²°í•©
        combined = "\n\n---\n\n".join(state["content"])

        logger.debug(f"   Total: {len(combined):,} chars")
        logger.debug(f"   Calling LLM...")

        try:
            # Models í´ë˜ìŠ¤ ì‚¬ìš©
            model_manager = Models()
            llm = model_manager.summarize_model()

            # ainvoke() ì‚¬ìš©
            response = await llm.ainvoke(Prompts.SYSTEMPROMPT.format(content=combined))

            return {
                "title": response.title,
                "result": response.result,
            }

        except Exception as e:
            logger.error(f"   âŒ LLM Error: {e}")
            return {"result": ""}
