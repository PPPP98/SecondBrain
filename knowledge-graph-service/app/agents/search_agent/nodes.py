from datetime import datetime
from .state import State
from .models import Models
from .prompts import Prompts
from .utils.time_utils import get_time_context
from .utils.neo4j_query_builder import (
    build_time_filter_cypher,
    build_similarity_search_cypher,
)
from app.db.neo4j_client import neo4j_client
from app.services.embedding_service import embedding_service
from typing import Any

from app.core.config import get_settings

import logging
import asyncio
import json
import traceback

settings = get_settings()
logger = logging.getLogger(__name__)
SEARCH_LIMIT = settings.search_limit
TOP_K = settings.top_k


class Nodes:
    """
    ê²€ìƒ‰ Agent Graph ë…¸ë“œ ì •ì˜
    Pre-Filter
    Simple Lookup
    Similarity Search
    Relevance Check
    Generate Response

    """

    @staticmethod
    async def pre_filter_node(state: State) -> State:
        """
        Pre-Filter

        ì‘ì—…:
        1. ì‹œê°„ ë²”ìœ„ ì¶”ì¶œ
        2. ê²€ìƒ‰ íƒ€ì… ê²°ì • (simple_lookup | similarity | direct_answer)
        3. ì¿¼ë¦¬ ì¬ì‘ì„± (similarityìš©, í’ë¶€í•œ ê²€ìƒ‰)
        """

        try:
            logger.debug(f"ğŸ” Pre-Filter - user: {state.get('user_id')}")

            # ì‹œê° ì •ë³´
            time_context = get_time_context()

            # LLM ëª¨ë¸
            models = Models()
            llm = models.get_prefilter_model()

            # í”„ë¡¬í”„íŠ¸
            prompt_text = Prompts.PRE_FILTER_PROMPT.format(
                query=state["original_query"],
                current_datetime=time_context["current_datetime"],
                weekday_korean=time_context["weekday_korean"],
                week_number=time_context["week_number"],
            )

            # LLM í˜¸ì¶œ
            logger.debug(f"ğŸ’¬ ë¶„ì„: {state['original_query']}")
            result = await llm.ainvoke(prompt_text)

            # í•„í„° êµ¬ì„±
            filters = {}
            if result.timespan:
                filters["timespan"] = {
                    "start": result.timespan.start,
                    "end": result.timespan.end,
                    "description": result.timespan.description,
                }
                logger.debug(f"ğŸ“… ì‹œê°„: {result.timespan.description}")

            # ë¡œê¹…
            logger.debug(f"ğŸ”€ íƒ€ì…: {result.search_type}")
            if result.search_type == "similarity" and result.query:
                logger.debug(f"âœï¸  ì¬ì‘ì„±: {result.query}")

            # State ì—…ë°ì´íŠ¸
            return {
                **state,
                "original_query": state["original_query"],
                "query": result.query if result.query else state["original_query"],
                "filters": filters,
                "search_type": result.search_type,
            }

        except Exception as e:
            logger.error(f"âŒ Pre-filter ì—ëŸ¬: {str(e)}")

            traceback.print_exc()

            # ê¸°ë³¸ê°’: similarity
            return {
                **state,
                "original_query": state.get("original_query", ""),
                "filters": {},
                "search_type": "direct_answer",
            }

    @staticmethod
    async def simple_lookup_node(state: State) -> State:
        """
        Simple Lookup ë…¸ë“œ: ì‹œê°„ í•„í„°ë¡œ Neo4j ê²€ìƒ‰

        ì‘ì—…:
        1. ì‹œê°„ í•„í„° ê¸°ë°˜ Cypher ì¿¼ë¦¬ ìƒì„±
        2. Neo4j ê²€ìƒ‰ ì‹¤í–‰
        3. ìµœëŒ€ 10ê°œ ê²°ê³¼ë¥¼ state["documents"]ì— ì €ì¥

        Returns:
            documents: ê²€ìƒ‰ëœ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ search_limitê°œ)
        """

        try:
            logger.debug("ğŸ” Simple Lookup ì‹œì‘")

            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            user_id = state.get("user_id")
            timespan = state.get("filters", {}).get("timespan")

            if not user_id:
                logger.error("user_idê°€ ì—†ìŠµë‹ˆë‹¤")
                raise ValueError("user_idê°€ í•„ìš”í•©ë‹ˆë‹¤")

            # Cypher ì¿¼ë¦¬ ìƒì„±
            cypher, params = build_time_filter_cypher(
                user_id=user_id,
                timespan=timespan,
                limit=SEARCH_LIMIT,
            )

            logger.debug(f"ğŸ“ Cypher:\n{cypher}")
            logger.debug(f"ğŸ“¦ Params: {params}")

            # Neo4j ê²€ìƒ‰
            with neo4j_client.get_session() as session:
                result = session.run(cypher, params)
                records = list(result)

            # ê²°ê³¼ í¬ë§·íŒ…
            documents = []
            for record in records:
                doc = {
                    "note_id": record["note_id"],
                    "title": record["title"],
                }

                if record["created_at"]:
                    doc["created_at"] = record["created_at"].isoformat()

                if record["updated_at"]:
                    doc["updated_at"] = record["updated_at"].isoformat()

                documents.append(doc)

            logger.debug(
                f"âœ… Simple Lookup ì™„ë£Œ: {len(documents)}ê°œ " f"(ìµœëŒ€ {SEARCH_LIMIT}ê°œ)"
            )

            if timespan:
                logger.debug(f"ğŸ“… ì‹œê°„ ë²”ìœ„: {timespan.get('description', 'N/A')}")

            return {
                **state,
                "documents": documents,
            }

        except Exception as e:
            logger.error(f"âŒ Simple Lookup ì—ëŸ¬: {str(e)}")
            import traceback

            traceback.print_exc()

            return {
                **state,
                "documents": [],
            }

    @staticmethod
    async def similarity_search_node(state: State) -> State:
        """
        Similarity Search ë…¸ë“œ: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰

        ì‘ì—…:
        1. ì¬ì‘ì„±ëœ ì¿¼ë¦¬ ì„ë² ë”© (EmbeddingService ì‚¬ìš©)
        2. Neo4j ë²¡í„° ê²€ìƒ‰ (Top-3)
        3. ê²°ê³¼ë¥¼ state["documents"]ì— ì €ì¥

        Returns:
            documents: ìœ ì‚¬ë„ ë†’ì€ ë…¸íŠ¸ Top-3
        """

        try:
            logger.debug("ğŸ” Similarity Search ì‹œì‘")

            # 1. íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            query = state.get("query", "")
            user_id = state.get("user_id")
            timespan = state.get("filters", {}).get("timespan")

            if not user_id:
                logger.error("user_idê°€ ì—†ìŠµë‹ˆë‹¤")
                raise ValueError("user_idê°€ í•„ìš”í•©ë‹ˆë‹¤")

            if not query:
                logger.warning("ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return {**state, "documents": []}

            logger.debug(f"ğŸ’¬ ê²€ìƒ‰ ì¿¼ë¦¬: {query}")

            # 2. ì¿¼ë¦¬ ì„ë² ë”© (EmbeddingService ì‚¬ìš©)
            logger.debug("ğŸ“Š ì„ë² ë”© ìƒì„± ì¤‘...")
            query_embedding, token_count = embedding_service.generate_embedding(query)

            logger.debug(
                f"âœ… ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: {len(query_embedding)}, í† í°: {token_count})"
            )

            # 3. Cypher ì¿¼ë¦¬ ìƒì„±
            cypher, params = build_similarity_search_cypher(
                embedding=query_embedding,
                user_id=user_id,
                timespan=timespan,
                limit=SEARCH_LIMIT,
            )

            logger.debug(f"ğŸ“ Cypher ì¿¼ë¦¬:\n{cypher}")
            logger.debug(f"ğŸ“¦ íŒŒë¼ë¯¸í„° (ì„ë² ë”© ì œì™¸): user_id={user_id}, limit={10}")

            # 4. Neo4j ë²¡í„° ê²€ìƒ‰
            logger.debug("ğŸ” Neo4j ë²¡í„° ê²€ìƒ‰ ì¤‘...")
            with neo4j_client.get_session() as session:
                result = session.run(cypher, params)
                records = list(result)

            # 5. ê²°ê³¼ í¬ë§·íŒ…
            documents = []
            for record in records:
                doc = {
                    "note_id": record["note_id"],
                    "title": record["title"],
                    "similarity_score": float(record["similarity_score"]),
                }

                if record["created_at"]:
                    doc["created_at"] = record["created_at"].isoformat()

                if record["updated_at"]:
                    doc["updated_at"] = record["updated_at"].isoformat()

                documents.append(doc)

            logger.debug(f"âœ… Similarity Search ì™„ë£Œ: {len(documents)}ê°œ ")

            if timespan:
                logger.debug(f"ğŸ“… ì‹œê°„ ë²”ìœ„: {timespan.get('description', 'N/A')}")

            # ìœ ì‚¬ë„ ì ìˆ˜ ë¡œê¹…
            if documents:
                logger.debug("ğŸ“Š ìœ ì‚¬ë„ ì ìˆ˜:")
                for i, doc in enumerate(documents, 1):
                    logger.debug(
                        f"  [{i}] {doc['title']}: {doc['similarity_score']:.3f}"
                    )
            else:
                logger.warning("âš ï¸  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

            return {
                **state,
                "documents": documents,
            }

        except Exception as e:
            logger.error(f"âŒ Similarity Search ì—ëŸ¬: {str(e)}")
            import traceback

            traceback.print_exc()

            return {
                **state,
                "documents": [],
            }

    @staticmethod
    async def relevance_check_node(state: State) -> State:
        """
        ì—°ê´€ì„± ì²´í¬ ë…¸ë“œ: LLMìœ¼ë¡œ ë¬¸ì„œ-ì§ˆë¬¸ ê´€ë ¨ì„± ê²€ì¦ (ë‹¨ìˆœí™”)

        ì‘ì—…:
        1. ê° ë¬¸ì„œì˜ titleê³¼ original_query ë¹„êµ (ë³‘ë ¬)
        2. LLMìœ¼ë¡œ ê´€ë ¨ì„± íŒë‹¨ (true/falseë§Œ)
        3. ê´€ë ¨ ìˆëŠ” ë¬¸ì„œë§Œ í•„í„°ë§

        Returns:
            documents: ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œë§Œ (0-3ê°œ)
        """

        try:
            logger.debug("ğŸ” ì—°ê´€ì„± ì²´í¬ ì‹œì‘")

            # 1. íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            documents = state.get("documents", [])
            original_query = state.get("original_query", "")

            if not documents:
                logger.warning("ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                return {**state, "documents": []}

            if not original_query:
                logger.warning("ì›ë³¸ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤")
                return state  # ì²´í¬ ìƒëµ

            logger.debug(f"ğŸ“š ì²´í¬í•  ë¬¸ì„œ: {len(documents)}ê°œ")
            logger.debug(f"ğŸ’¬ ì›ë³¸ ì§ˆë¬¸: {original_query}")

            # 2. LLM ëª¨ë¸ ì¤€ë¹„
            models = Models()
            relevance_model = models.get_relevance_check_model()

            # 3. ê° ë¬¸ì„œ ì²´í¬ (ë³‘ë ¬)
            async def check_single_document(doc: dict, idx: int) -> tuple[dict, bool]:
                """ë‹¨ì¼ ë¬¸ì„œ ì²´í¬"""
                try:
                    title = doc.get("title", "")

                    # í”„ë¡¬í”„íŠ¸ ìƒì„±
                    prompt = Prompts.RELEVANCE_CHECK_PROMPT.format(
                        query=original_query, title=title
                    )

                    # LLM í˜¸ì¶œ
                    result = await relevance_model.ainvoke(prompt)

                    logger.debug(
                        f"  [{idx+1}] {title}: "
                        f"{'âœ… ê´€ë ¨' if result.is_relevant else 'âŒ ë¬´ê´€'}"
                    )

                    return doc, result.is_relevant

                except Exception as e:
                    logger.error(f"ë¬¸ì„œ ì²´í¬ ì‹¤íŒ¨ [{doc.get('title')}]: {e}")
                    # ì—ëŸ¬ ì‹œ ê´€ë ¨ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬
                    return doc, False

            # ë³‘ë ¬ ì²˜ë¦¬
            logger.debug("ğŸ”„ ë³‘ë ¬ ì²´í¬ ì¤‘...")
            tasks = [check_single_document(doc, i) for i, doc in enumerate(documents)]
            results = await asyncio.gather(*tasks)

            # 4. ê´€ë ¨ ìˆëŠ” ë¬¸ì„œë§Œ í•„í„°ë§
            filtered_documents = [doc for doc, is_relevant in results if is_relevant]

            logger.debug(
                f"âœ… ì—°ê´€ì„± ì²´í¬ ì™„ë£Œ: "
                f"{len(filtered_documents)}/{len(documents)}ê°œ ê´€ë ¨ ìˆìŒ"
            )

            if filtered_documents:
                logger.debug("ğŸ“ ê´€ë ¨ ë¬¸ì„œ:")
                for i, doc in enumerate(filtered_documents, 1):
                    logger.debug(f"  [{i}] {doc.get('title')}")
            else:
                logger.warning("âš ï¸  ê´€ë ¨ ìˆëŠ” ë¬¸ì„œ ì—†ìŒ")

            return {
                **state,
                "documents": filtered_documents,
            }

        except Exception as e:
            logger.error(f"âŒ ì—°ê´€ì„± ì²´í¬ ì—ëŸ¬: {str(e)}")

            traceback.print_exc()
            # ì—ëŸ¬ ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return state

    @staticmethod
    async def generate_response_node(state: State) -> State:
        """
        ì‘ë‹µ ìƒì„± ë…¸ë“œ: ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬ (1-2ë¬¸ì¥)

        ì¼€ì´ìŠ¤:
        1. direct_answer: ê²€ìƒ‰ ìœ ë„ ë©”ì‹œì§€
        2. ë¬¸ì„œ ì—†ìŒ: ê²€ìƒ‰ ì‹¤íŒ¨ ì•ˆë‚´
        3. ë¬¸ì„œ ìˆìŒ: ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½

        Returns:
            response: 1-2ë¬¸ì¥ ì§§ì€ ì‘ë‹µ
        """

        try:
            logger.debug("ğŸ“ ì‘ë‹µ ìƒì„± ì‹œì‘")

            # íŒŒë¼ë¯¸í„°
            documents = state.get("documents", [])
            original_query = state.get("original_query", "")
            search_type = state.get("search_type", "")

            logger.debug(f"ğŸ’¬ ì§ˆë¬¸: {original_query}")
            logger.debug(f"ğŸ”€ íƒ€ì…: {search_type}")
            logger.debug(f"ğŸ“š ë¬¸ì„œ: {len(documents)}ê°œ")

            # LLM ëª¨ë¸
            models = Models()
            llm = models.get_response_model()

            # ========================================
            # Case 1: Direct Answer (ê²€ìƒ‰ ìœ ë„)
            # ========================================
            if search_type == "direct_answer":
                logger.debug("ğŸ¯ ì¼€ì´ìŠ¤: ê²€ìƒ‰ ìœ ë„")

                prompt = Prompts.GENERATE_DIRECT_ANSWER_PROMPT.format(
                    query=original_query
                )

                logger.debug(f"ğŸ“„ í”„ë¡¬í”„íŠ¸:\n{prompt}")

                response = await llm.ainvoke(prompt)
                response_text = (
                    response.content if hasattr(response, "content") else str(response)
                )

                logger.debug(f"âœ… ê²€ìƒ‰ ìœ ë„ ì™„ë£Œ: {response_text}")

                return {**state, "response": response_text}

            # ========================================
            # Case 2: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
            # ========================================
            if not documents:
                logger.debug("âš ï¸  ì¼€ì´ìŠ¤: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

                response_text = Prompts.GENERATE_NO_RESULT_RESPONSE

                logger.debug(f"âœ… ì•ˆë‚´ ë©”ì‹œì§€: {response_text}")

                return {**state, "response": response_text}

            # ========================================
            # Case 3: ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬
            # ========================================
            logger.debug("ğŸ“„ ì¼€ì´ìŠ¤: ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬")

            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_parts = []
            for i, doc in enumerate(documents[:TOP_K], 1):
                title = doc.get("title", "ì œëª© ì—†ìŒ")
                context_parts.append(f"{title}")

            context = "\n".join(context_parts)

            logger.debug(f"ğŸ“‹ ì»¨í…ìŠ¤íŠ¸:\n{context}")

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = Prompts.GENERATE_RESPONSE_PROMPT.format(
                query=original_query, context=context
            )

            logger.debug(f"ğŸ“„ í”„ë¡¬í”„íŠ¸:\n{prompt}")

            # LLM í˜¸ì¶œ
            logger.debug("ğŸ¤– LLM í˜¸ì¶œ ì¤‘...")
            response = await llm.ainvoke(prompt)
            response_text = (
                response.content if hasattr(response, "content") else str(response)
            )

            logger.debug(f"âœ… ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬ ì™„ë£Œ")
            logger.debug(f"ğŸ“¤ ì‘ë‹µ ({len(response_text)}ì): {response_text}")

            return {**state, "response": response_text}

        except Exception as e:
            logger.error(f"âŒ ì‘ë‹µ ìƒì„± ì—ëŸ¬: {str(e)}")
            traceback.print_exc()

            # ========================================
            # Fallback: ë‹¨ìˆœ ë¦¬ìŠ¤íŠ¸
            # ========================================
            documents = state.get("documents", [])

            if documents:
                # ê°„ë‹¨í•œ í´ë°± ë©”ì‹œì§€
                titles = [doc.get("title", "ì œëª© ì—†ìŒ") for doc in documents]

                if len(documents) == 1:
                    fallback = f"ë…¸íŠ¸ 1ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {titles[0]}"
                elif len(documents) <= 3:
                    fallback = (
                        f"ë…¸íŠ¸ {len(documents)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {', '.join(titles)}"
                    )
                else:
                    fallback = f"ë…¸íŠ¸ {len(documents)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {', '.join(titles[:3])} ì™¸ {len(documents)-3}ê°œ"

                logger.warning(f"âš ï¸  í´ë°± ì‘ë‹µ: {fallback}")

                return {**state, "response": fallback}
            else:
                fallback = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                logger.warning(f"âš ï¸  í´ë°± ì‘ë‹µ: {fallback}")

                return {**state, "response": fallback}

    @staticmethod
    async def check_search_type(state: State) -> State:
        """
        MCP agent node

        1. ì…ë ¥ ì¿¼ë¦¬ê°€ ìˆì„ ë•Œ
        ìœ ì‚¬ë„ ê²€ìƒ‰
        2. timespanë§Œ ì¡´ì¬í•  ë•Œ
        ê¸°ê°„ ê²€ìƒ‰
        """
        query = state.get("query")
        timespan = state.get("filters", {}).get("timespan")

        if query:
            return {
                **state,
                "search_type": "similarity",
            }
        elif timespan:
            return {
                **state,
                "search_type": "simple_lookup",
            }
        else:
            return {
                **state,
                "search_type": "end",
            }
