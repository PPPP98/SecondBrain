Spring Batch 학습 정리

1. Spring Batch

    1-1. 대규모 데이터의 '일괄 처리(Batch Processing)'를 위해 설계된 스프링 산하의 프레임워크

    1-2. 사용자의 개입 없이, 정해진 스케줄에 따라 대량의 데이터를 안정적으로 처리하는 것이 목표

    1-3. 실시간 API 처리와는 반대되는 개념으로, 데이터 정합성과 신뢰성이 중요함


2. 주요 아키텍처 및 구성 요소

    - JobLauncher: 배치를 실행시키는 주체, 외부 요청(스케줄러 등)을 받아 Job을 구동함

    - Job: 하나의 배치 작업을 의미하는 최상위 단위. 내부에 하나 이상의 Step을 가짐

    - Step: Job을 구성하는 독립적인 실행 단계. 실제 데이터 처리 로직(Read-Process-Write)이 이뤄지는 공간. 하나의 Step이 성공해야 다음 Step으로 넘어감.

    - JobRepository: Job과 Step의 실행 정보를 담는 저장소. 어떤 Job이 언제 시작해서 성공/실패했는지, 몇 번의 시도가 있었는지 등의 모든 메타데이터를 DB에 기록함. 이 덕분에 실패한 지점부터 재시작하는 것이 가능


3. Step의 핵심 동작 원리: Chunk 지향 처리 

    - Spring Batch의 가장 중요한 개념
    데이터를 한 번에 하나씩 처리하지 않고 특정 묶음 단위로 처리하는 방식

    - 흐름: Read -> Process -> Write

    - ItemReader: 데이터 소스(DB, 파일 등)에서 데이터를 하나씩 읽어온다.

    - ItemProcessor: 읽어온 데이터를 비즈니스 로직에 따라 하나씩 가공한다. 이 단계는 선택사항고 데이터 변환이 필요 없을 시 생략 가능

    - 읽고 가공한 데이터가 정해진 Chunk 크기만큼 쌓일 때까지 1, 2번을 반복

    - ItemWriter: Chunk 크기만큼 쌓인 데이터를 한 번에 대상 시스템에 기록. 이 쓰기 작업은 하나의 트랜잭션으로 묶임

    - Chunk: 하나의 트랜잭션에서 처리될 아이템의 묶음
     ,commit-interval 속성으로 크기를 지정

4. Spring Batch를 사용하는 이유

    - 대용량 데이터 처리: Chunk 단위 처리로 메모리 사용량을 최적화하여 OutOfMemoryError를 방지하고, 대규모 데이터를 효율적으로 다룰 수 있음

    - 안정성 및 재시작 기능: JobRepository가 모든 작업 내역을 기록하므로, 작업 실패 시 원인을 파악하고 실패한 지점부터 작업을 재개할 수 있음

    - 트랜잭션 관리: Chunk 단위로 트랜잭션을 제어하여 데이터 정합성을 강력하게 보장됨, 처리 도중 오류가 발생하면 해당 Chunk의 트랜잭션 전체가 롤백

    - 표준화: 데이터 일괄 처리에 필요한 공통 기능(로깅, 재시도, 흐름 제어 등)을 표준화된 방식으로 제공하여 개발자가 비즈니스 로직에만 집중할 수 있게 해줌